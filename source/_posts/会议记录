一、流程制度
	1.提测分支合并最新trunk与否
		当trunk被合代码时，目前cache会有资深开发code review；
	2.是否涉及字段修改
	3.是否打印多余日志，可能会影响到性能
	4.是否涉及缓存
	5.数据配置是否修改
	6.verify是否通过
	7.searchhub的pc是否生效
	8.开发是否确认过代码diff
	9.如果有未覆盖代码，需要开发确认

	各个核心模块做checklist：cache，searchub，vrqo，openhub，nginx，node

	wiki：周二@费晓收集

二、错误类型
	1.变量未初始化
	2.空指针
	3.越界
	4.下游新上数据源时，跨机房连接超时（配置检查，配置不能硬编码在代码中）
	5.接口字段错误，造成展示错误（缺少字段或者字段传递错误）
	6.死循环
	7.core检查：
		记录core，及时在wiki上更新core；
		如果出core，由开发判断是否是本次修改引起；
		目前在cache中，core零容忍，具体可由宋南确认；

	8.内存泄漏
	9.数据热加载：文件过大，频繁加载时，可能引起内存未释放，或者gc频繁。
	10.日志过大，线上history文件为空，以及导致hadoop中1小时内日志无法压缩完成，之后下一小时循环压缩。
	11.nginx下游模块下线，nginx长期不重启会存在风险。比如下游模块缩环，域名不存在，nginx需要更改配置文件后重启。
	12.各模块调试均没有问题，但是上线后数据未打上标记，导致丢vr


	应对方案：
	1.公共异常数据集：核心模块（cache、searchhub、vrqo、openhub、nginx、node）每次测试时例行运行 @费晓 周三
	2.最小数据集：核心模块（cache、searchhub、vrqo、openhub、nginx、node）每次测试时例行运行


	测试方法和工具收集整理：
	1.未覆盖代码的确认（关注for循环和while循环）
	2.对新增代码的循环进行检查
	3.代码覆盖率基限是85%
	4.死循环代码 @海峰调研

三、数据完备性：桩数据
	预期：保证vr桩数据能够覆盖所有vr类型； @金铭找孟孟沟通，最迟6月15日
		 确保公共服务（cache、searchhub、node、nginx、vrqo、openhub以及一些小模块）数据和代码及时更新，定期存活状态检测；

	vr桩数据：内部和外部多命中

	外部多命中：积累到redis
	内部：缓存桩，按qps比例线上真实去取。积累到数据库，redis做缓存。

	3600+个vr：能否命中

	

